### Redis数据结构应用场景

[参考](https://mp.weixin.qq.com/s/iWGj-WuTg81TvJodMsA_3g)

String：简单数据转化成string再存储，原子自增或者自减去，定时过期，分布式锁；

list：有序、可以重复。生产者消费者模型、有序消息、用户排队；基于Linked Lists实现，头尾操作极速，检索非常慢，故不要用list存大量数据并进行检索。

set：无序、不可以重复。去重、交集、并集、差集、随机获得一个元素；

hash：结构化数据存储；

zset：set数据结构加了core，可以用于排行榜；有序集合的排序默认按照字段顺序。

Bitmaps：布隆过滤器。

### Redis分布式锁

由于Redis是单线程模型，命令操作原子性，所以利用这个特性可以很容易的实现分布式锁。 

~~~JAVA
SET key uuid NX PX timeout
~~~

命令中的NX表示如果key不存在就添加，存在则直接返回。PX表示以毫秒为单位设置key的过期时间。设置过期时间是防止获得锁的客户端突然崩溃掉或其他异常情况，导致redis中的对象锁一直无法释放，造成死锁。Key的值需要在所有请求锁服务的客户端中，确保是个唯一值。 这是为了保证拿到锁的客户端能安全释放锁，防止这个锁对象被其他客户端删除。
举个例子：

> A客户端拿到对象锁，但在因为一些原因被阻塞导致无法及时释放锁。
> 因为过期时间已到，Redis中的锁对象被删除。
> B客户端请求获取锁成功。
> A客户端此时阻塞操作完成，删除key释放锁。
> C客户端请求获取锁成功。

这时B、C都拿到了锁，因此分布式锁失效。
要避免例子中的情况发生，就要保证key的值是唯一的，**只有拿到锁的客户端才能进行删除**。 基于这个原因，普通的del命令是不能满足要求的，我们需要一个能判断客户端传过来的value和锁对象的value是否一样的命令。遗憾的是Redis并没有这样的命令，但可以通过Lua脚本来完成：

~~~java
if redis.call("get",KEYS[1]) == ARGV[1] then 
   return redis.call("del",KEYS[1])
 else 
   return 0
 end
~~~

逻辑很简单，获取key中的值和参数中的值相比较，相等删除，不相等返回0。

### redlock

所有分布式锁中唯一能让面试官高潮的实现方式。上一章节中这类锁最大的缺点就是它加锁时只作用于一个Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况

- 在Redis的master节点获得锁
- 加锁的key没有同步到slave节点
- mater故障，发生故障转移，slave节点升级成master节点
- 导致锁丢失

正因为这样，redlock应运而生，我们假设有N个Redis master，这些节点完全互相独立，不存在主从复制或者其他集群协调机制，我们确保将在N个实例上使用与在Redis单例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时宕机。实现大致如下：

- 获取当前时间
- 依次尝试从5个实例中，使用相同的key和**唯一性的value**（例如UUID）获取锁。当向Redis请求获取锁时，设置一个网络超时时间，如果超过超时时间，客户端应尽快尝试去另外的一个Redis实例请求获得锁
- 此时的时间减去步骤1的时间得出获取锁使用的时间。**当且仅当从大多数**（N/2+1，这里是三个节点）**的Redis节点都获取锁**，**并且获取锁使用的时间小于锁失效的时间，锁才算获取成功**
- 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。
- 如果因为某些原因，获取锁失败（没有成功在大多数节点上面获得锁），客户端应该在**所有实例上进行解锁**（尽管某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获得锁）。

redisson已经对redlock算法封装，源码可以进行参考。

> 使用分布式锁无非就两个场景：
>
> 1、要性能：拥有了这把锁之后使得你不会重复劳动，比方说两个节点同时做了这个job，那么这个job增加了你的成功；
>
> 2、要正确性：拥有这把锁可以防止并发操作污染你的系统或者数据；
>
> 如果是第一种情况，那么没啥必要使用redlock，它成本高且复杂，只用一个Redis实例即可，最多加个从，即使出现主崩溃，锁丢失的情况下，也无所谓。

### Redis持久化

[非常有参考性，里面还提到了问题排查和性能优化](https://mp.weixin.qq.com/s/e-WKqzzeElBJAY3nrDkyBg)

RDB：适用于数据备份，无法做到实时性。客户端显式触发（save,bgsave）和自动触发(配置文件)、主从同步的时候。

AOF：常用，可以做到实时性，重写机制重要，缓冲区同步策略：always性能最差，everysec性能和数据安全的平衡点，no基于系统的落盘策略。

服务器重启，数据恢复：优先加载AOF，当没有AOF才会加载RDB。

fork操作优化：RDB和重写AOF文件，都需要FORK操作，fork操作会阻塞Redis的所有命令执行，直到fork操作结束，优化点是必须减少fork操作的时间。

1. 优先使用物理机或者高效支持fork操作的虚拟机技术；
2. 控制Redis最大内存，一般设置为10个G；fork操作耗时和Redis最大内存成反比；
3. 降低fork的频率；

子进程开销：fork完后会创建子进程，子进程会有CPU、内存、磁盘开销。

1. 不要和其他高硬盘负载的服务放在同一台机器上面，比如MQ、数据库；
2. 在重写期间，建议更改缓冲区同步策略为no；
3. 建议使用SSD；

### Redis序列化

[参考](https://blog.csdn.net/f641385712/article/details/84679456)

1. StringRedisTemplate默认采用的是String的序列化策略，保存的key和value都是采用此策略序列化保存的，StringRedisSerializer
2. RedisTemplate默认采用的是JDK的序列化策略，保存的key和value都是采用此策略序列化保存的。JdkSerializationRedisSerializer，优点是反序列化时不需要提供（传入）类型信息(class)，但缺点是需要实现Serializable接口，还有序列化后的结果非常庞大，是JSON格式的5倍左右，这样就会消耗redis服务器的大量内存，还有序列化后的结果是二进制数据，对开发非常不友好。
3. 推荐使用：StringRedisSerializer和GenericJackson2JsonRedisSerializer（类似于Jackson2JsonRedisSerializer，优点是速度快，序列化后的字符串短小精悍，不需要实现Serializable接口，不用自己手动指定对象的Class）。
4. 自己实现序列化：protobuf效率非常高，用protobuf序列化后的大小是json的10分之一，xml格式的20分之一，是二进制序列化的10分之一。缺点是下载一个编译软件，对传输对象进行编译生成一个proto文件，每当传输对象修改了，proto文件也必须修改。protostuff的出现，弥补了protobuf的缺点。

### 缓存穿透

1. [布隆过滤器](https://www.jianshu.com/p/2104d11ee0a2)，特点是高效地插入和查询，可以用来告诉你 “**某样东西一定不存在或者可能存在**”。常见的适用常见有，利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。
2. 简单粗暴：缓存不存在的key值。过期时间会比较短，最长不超过五分钟。
3. 根据缓存key的设计规则，将不符合规则的key进行过滤。

### 缓存雪崩

缓存在同一时间失效或者缓存服务器宕机，请求都到了后端数据源，负载过大，压垮数据库

1. 发现缓存中取不到，进行加锁排队或者队列的方式保证缓存的单进程操作，避免并发请求全部落到后端存储系统，但是这种方式会对性能有损耗；

2. 将缓存失效的时间分散，降低每一个缓存过期时间的重复率；

3. 如果是因为缓存服务器故障导致的原因，一方面保证高可用（Redis的哨兵节点），另一方面采用多级缓存。

4. 补充：

   > - 事前：尽量保证整个Redis集群的高可用，发现机器宕机尽快补上。选择合适的内存淘汰策略
   > - 事中：本地ehcache缓存+hystrix限流&降级，避免MySQL崩溃。（hystrix限流组件，假设设置了2000个请求每秒，那么一秒5000个请求，2000个可以正常进行数据库请求，另外3000个走降级组件，比如返回兜底数据）
   > - 事后：利用Redis持久化机制保存的数据尽快恢复缓存

### 缓存击穿

缓存击穿和缓存雪崩的区别在于，击穿指的是某些key是非常热点的数据，一旦时间过期，不得不去数据库load，恰好这个时间点有非常多的请求过来，可能会瞬间把后端DB压垮。解决方案：

~~~java
// 使用互斥锁
public String get(key) {
      String value = redis.get(key);
      if (value == null) { //代表缓存值过期
          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
		  if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
               value = db.get(key);
                      redis.set(key, value, expire_secs);
                      redis.del(key_mutex);
              } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
                      sleep(50);
                      get(key);  //重试
              }
          } else {
              return value;      
          }
 }

// 逻辑上永远不过期：发现要过期了，使用后台线程进行缓存重构。
String get(final String key) {  
        V v = redis.get(key);  
        String value = v.getValue();  
        long timeout = v.getTimeout();  
        if (v.timeout <= System.currentTimeMillis()) {  
            // 异步更新后台异常执行  
            threadPool.execute(new Runnable() {  
                public void run() {  
                    String keyMutex = "mutex:" + key;  
                    if (redis.setnx(keyMutex, "1")) {  
                        // 3 min timeout to avoid mutex holder crash  
                        redis.expire(keyMutex, 3 * 60);  
                        String dbValue = db.get(key);  
                        redis.set(key, dbValue);  
                        redis.delete(keyMutex);  
                    }  
                }  
            });  
        }  
        return value;  
}
~~~



### Redis和数据库一致性问题

[参考](https://blog.csdn.net/qq_37779352/article/details/82977921)

1. 首先，可以肯定的是，redis中的数据和数据库中的数据不可能保证事务性达到统一的，这个是毫无疑问的，所以在实际应用中，我们都是基于当前的场景进行权衡降低出现不一致问题的出现概率；
2. 更新缓存还是让缓存失效：更新缓存的代价是否大做决定的，代价指的是是否需要很复杂的计算或者复杂的逻辑获取最新的结果；
3. 先操作数据库还是先操作缓存：更新数据库和更新缓存这两个操作，是无法保证原子性的，所以我们需要根据当前业务的场景的容忍性来选择。也就是如果出现不一致的情况下，哪一种更新方式对业务的影响最小，就先执行影响最小的方案。
   - 先更新数据库，再更新缓存。A线程更新数据库，B线程更新数据库，B线程更新缓存，A线程更新缓存。
   - 先删除缓存，再更新数据库。A线程删除缓存，B线程读取数据库并且写入缓存，A线程更新数据库，脏数据已经进入缓存中。解决方案：延时双删，A线程更新数据库后，休眠一秒（异步），再删除缓存，把这一秒中的脏数据进行清理，一秒怎么确定，具体该休眠多久，一般读数据耗时加锁几百毫秒即可。
   - 先更新数据库，再删除缓存。一般情况下使用这种。如果删除缓存失败，使用消息队列的方式，进行重试操作。业务耦合度低一点的方式，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。

### 分布式

#### 主从复制

#### 哨兵机制

#### Redis-Cluster

客户端分片-》简单，hash(key)取模，不支持动态增删节点，路由逻辑和存储逻辑耦合

代理分片（codis）-》路由逻辑跟Redis-cluster类似，把key分成N个槽，每个槽对应一个分组，一个分组对应于一个或者一组Redis实例。

Redis-cluster-》hash(key)计算出槽，再根据槽找到对应的Redis实例。Redis-cluster既没有用hash取模，也没有用一致性hash，而是采用虚拟槽来实现的。key与槽的关系永远不会变，槽与Redis的关系可以变。

Redis-cluster既能够实现主从的角色分配，又能够实现主从切换（投票机制完成slave到master的角色提升），相当于集成了replication和sentinel的功能。

Redis-cluster优点：无中心化架构、动态调整数据分布、可以扩展、高可用（主从切换）

Redis-cluster缺点：client实现复杂，client需要保存槽与Redis实例的对应关系，并及时更新。数据通过异步复制，不保证数据的强一致性。多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。很容易导致数据分布不均衡，因为是根据KEY进行hash计算的，如果某个key有巨大的set、list，无法进行拆分。

> hash算法：
>
> 哈希后取模：一旦节点数量变化，新增或者减少，由于取模的N发生变化，数据需要重新分布。
>
> 一致性hash：新增或者减少节点，只要少部分的数据重新分布。在分布式系统中，dubbo负载均衡某种策略就是使用了这个。解决了新增或者删除节点，数据都需要重新分布的问题。一致性hash容易出现hash倾斜的问题，解决办法是引入虚拟节点。

### 其他

Redis内存回收策略？

1. 默认是当内存不够时候，返回错误
2. lru(Least recently used,最近最少使用)：最近最少使用的数据删除，适合场景，热点数据相对比较明显
3. 随机：对key的访问概率差不多
4. 已经设置过期时间：随机、最近最少使用、将要过期的数据

Redis是单线程，性能为什么这么快？

1. cpu并不是Redis的瓶颈，而在于网络和内存

2. 非阻塞的IO多路复用：reactor设计模型，Java中的selector。单线程监听多个socket，任何一个socket发生事件（比方说读事件），就会有专门的事件处理器（读事件处理器）进行处理。一般来说，socket事件会放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

   多个socket、IO多路复用程序、文件事件分派器、事件处理器

3. 避免线程竞争和上下文切换

lua脚本？

1. 解决效率问题：减少网络传输，把命令写到脚本中，发给Redis服务器
2. 解决原子性问题：脚本作为一个整体，脚本中的几条命令，不会被其他客户端打断
3. 复用性

Hashtags？

我们知道执行MSET操作是原子性的。但是在redis-cluster的情况下，我们仍然可以执行MSET操作，但是并不是原子性的，会存在某些key成功，某些失败，原因是多个key被映射到了不同的机器节点上面。
   解决方案：
引入了hashTags的概念，当一个key包含 {} 的时候，就不对整个key做hash，而仅对 {} 包括的字符串做hash，比如：user:{user1}:id、user:{user1}.name

redission?

Redisson它除了常规的操作命令以外，还基于redis本身的特性去实现了很多功能的封装，比如分布式锁、原子操作、布隆过滤器、队列等等。

过期时间？

定期删除：每隔100ms随机抽取一些设置了过期时间的key，检查是否过期，如果过期就删除。

惰性删除：系统去查一下key，如果key已经过期了，才会把他给删除了。

Redis的内存分配？

数据、本身运行需要的内存、缓冲内存（aof内存缓冲区，进行aof重写时，保存最近的写入命令）、内存碎片。