### Debezium

基于Debezium Mysql Kafka Connector获取MySQL数据流，对数据流进行异构处理。[概念](https://blog.csdn.net/nilin99/article/details/78224785?locationNum=5&fps=1)

> Debezium是一个开源项目，为捕获数据更改(Capture Data Change，CDC)提供了一个低延迟的流式处理平台，通过安装配置Debezium监控数据库，可以实时消费行级别(row-level)的更改。身为一个分布式系统，Debezium也拥有良好的容错性。
>  Debezium的源端(即支持监控哪些数据库) : MySQL，MongoDB，PostgreSQL，Oracle，SQL Server
>  Debezium的目标端(即可以数据导入端) : Kafka
>  Debezium的应用 : 实时同步数据，实时消费数据

 OLTP迁移 MySQL数据--->POSTGRES数据

全文检索,搜索引擎建立 MySQL->ElasticSearch(全文搜索引擎)

>  框架使用：
>  Vert.x异步驱动 基于netty的全异步框架
>  DruidDatasource
>  KafkaClient
>  ZkClient
>  Guice IOC
>  Guava Eventbus
>  Lombok（结合IDE使用）

总结：

把MySQL的binlog发到kafka的topic上面，然后stream消费，并且存储到pgsql上面。由于PostgreSQL的功能强大，支持并行计算、空间数据处理、文本分析、数据挖掘、机器学习、复杂查询、冷热分离存储、分布式架构(citus, greenplum, xl)等。
kafka必须要依赖zookeeper：1、brocker注册；2、topic注册；3、生产者消费者负载均衡；4、消费消息offset记录；5、消费者注册

### 背景

所有的实例都集中在一台机器上面，导致了一下问题：

1、由于部分实例查询慢，导致其他实例受影响；

2、数据量全部集中在一台机器上，无法水平扩展；

3、运维困难（主从、备份、高可用等维护）；

因此需要按照实例场景和领域进行拆分，经过调查发现存在如下困难：

1、跨库查询；

2、跨库存储过程；

3、代码依赖（代码中存在跨库查询）；

4、缺少其他数据库服务器（仅有一主一从）；

5、本地配置困难。

线上情况：

单个数据库实例存放了多个数据库已经按照业务领域进行了拆分：数据集中在风控和财务库。

机器配置：一主一从，两天机器配置相同，内存120G，CPU40核心，硬盘2T。

连接情况：95%主库，5%从库。

跨库查询情况：涉及到10个库，51张表。

解决思路：

1、解决跨库查询，系统间调用的方式；

2、找到所有的解决不了的跨库查询，并且列举所有涉及到的表；

3、实时同步MySQL所有涉及到的数据到PG数据库；

4、查询跨库涉及到的表，从查询MySQL转到查询PG，并且做好开关，遇到问题随时切回去。

技术选型：debezium mysql kafka connector

1、支持全量+增量同步，减少了全量的开发步骤；

2、支持实时同步；

3、开源技术已经稳定还在迭代中；

4、PG更适合做多表连接查询，join查询，复杂查询，SQL查询基本无需要较大的修改即可迁移。

### 方案设计

![image-20190812160526893](http://ww1.sinaimg.cn/large/006tNc79ly1g61pmjevg7j316g0pm47z.jpg)

- 基本原理：MySQL binlog->kafka数据流->解析->处理->pg
- 高可用设计：zk<-同步协调->streamprocessor
- 失败处理：忽略处理-人工补偿、定点回溯、重新回溯。
- 通过ZK反馈和同步集群的工作，包括不同内容的同步器、同步位置的重置、暂停和继续。
- 通过work同步器拉取kafka数据处理，经过parser解析器转换为可识别的数据，由processor处理器负责将数据写入其他数据库。
- 允许一个进程存在多个同步器，每张数据表应有自己的worker同步器，worker同步器托管于workpool工作和管理声明周期。
- 后期可以用于建立搜索引擎es，建立缓存系统，数据流开放给数据部分分析。

![image-20190812161401900](http://ww1.sinaimg.cn/large/006tNc79ly1g61pmn2vkxj30u00uyamk.jpg)

### 施工方案

1、准备期：不停服的情况下，把涉及跨库的表全量同步到PG；
2、过渡期：修改原代码的跨库查询语句(改成从PG查询)，并保证查询出来的数据一致，同时，对原有跨库查询保留，并开发对应的切换器，实现修改后的查询功能和原查询功能的切换；
3、观察期：修改后的跨库查询语句是否正确，出现问题，立即切换；
4、拆分期：尝试拆分个别数据库；
5、稳定期：所有数据库，拆分完毕。

### 服务器硬件

风控数据库保留原来数据库、财务数据迁移到新库、基础数据迁移到RDS

1、风控数据库保留原来数据库，主从不变；
2、财务数据迁移到新库，配置是风控数据一半；
3、基础数据迁移到RDS，CPU8*2GHZ，内存8个G，硬盘500G。
4、kafka和ZK配置：CPU4*2GHZ，内存4个G，硬盘500G。

### 方案预计效果

- 提升查询性能

  > 1、提升查询性能：提升连接情况，及并发时的资源竞争问题
  > 2、提升查询性能：提升MySQL数据预热，两台服务器可以使用更过数据预加载
  > 3、提升查询性能：提升硬盘查询速度，数据量降低了，单服务器磁盘查找速度提升

- 提升稳定性

  > 1、提升稳定性：多数据源按场景分离，相互不干扰
  > 2、提升稳定性：避免了单台过热时，影响其他数据库查询

- 释放存储瓶颈

  > 按业务拆分数据库，后期可以继续使用该方案继续拆分子领域

- 释放了水平扩展能力

  > 应用水平扩展能力不再受限于数据库