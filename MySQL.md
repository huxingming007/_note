### 索引

#### 数据结构

- 二叉树：第一个节点的选择很重要，如果插入的数据很有连续性的话，并没有起到二分查找的作用，比方连续插入1、2、3、4、5、6，就变成了一条直线；

- 平衡二叉树：解决了二叉树插入连续性的问题，但是还有其他缺点，太深了（高度太高，磁盘IO耗时大），太小了（磁盘块即节点存的数据很少，没有利用磁盘的预读能力即局部性原理），hashmap中的红黑树就是一种平衡二叉树；

- B树和B+树：解决了高度问题，磁盘预读问题。

  > B+树关键字搜索采用闭合区间；
  >
  > B+树的非叶子节点只保存关键字<!--没有存真实数据的地址信息-->和子节点的引用<!--非叶子节点可以存很多关键字，使高度更低，IO操作更少-->；
  >
  > B+树关键字对应的数据存在叶子节点中；
  >
  > B+树叶子节点是顺序排列，并且相邻节点具有顺序引用的关系；

- B+树在myisam的体现形式和innodb不一样的地方

  > innodb是以主键索引来组织数据的存储（数据库表行中的顺序是和索引顺序相同），索引和数据都是存在一个文件中（IBD），用主键索引可以直接定位，用辅助索引先定位查到这条记录的主键，然后再用主键索引定位记录；
  > myisam索引和数据存的是两个文件，分别是myi和myd，主键索引和辅助索引定位找到这个关键字，然后根据存储的记录地址，去myd查询记录；

![左边是innodb、右边是myisam](http://ww3.sinaimg.cn/large/006tNc79ly1g61ngfnw3uj30po0bkwfk.jpg) 

#### 补充

列的离散性：越大越适合做索引，比方说性别：男、女，离散性很差，即使加了索引，存储引擎会执行计划选择不通过索引查询；

最左匹配原则；

联合索引：1、经常用的列优先 【最左匹配原则】 2，选择性(离散度)高的列优先【离散度高原则】 3，宽度小的列优先【最少空间原则】一个磁盘块（节点）可以放更多的关键字；

覆盖索引：如果查询列可以直接通过节点中的关键字返回，即为覆盖索引。优点：覆盖索引可减少数据库IO，将随机IO变为顺序IO，可提高查询性能；

> 索引列的数据长度能少则少。 
> 索引一定不是越多越好，越全越好，一定是建合适的。
> 匹配列前缀可用到索引 like 9999%，like %9999%、like %9999用不到索引; 
> Where 条件中 not in 和 <>操作无法使用索引;
> 匹配范围值，order by 也可用到索引; 
> 多用指定列查询，只返回自己想到的数据列，少用select *; 
> 联合索引中如果不是按照索引最左列开始查找，无法使用索引; 
> 联合索引中精确匹配最左前列并范围匹配另外一列可以用到索引; 
> 联合索引中如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引;

### 存储引擎

> 插拔式的插件方式，每个表都可以指定专用的存储引擎。

#### myisam

mysql5.5版本之前的默认存储引擎。特点：

> count(*)无需进行数据的扫描
>
> 数据和索引分开存储
>
> 表级锁
>
> 不支持事务

#### innodb

mysql5.5版本之后的默认存储引擎

> 事务、行级锁、聚集索引（主键索引）方式进行数据存储、支持外键关系保证数据完整性



### mysql查询优化

查询执行的路径：客户端连接（半双工） - 查询缓存 - 解析器 - 查询优化处理 - 查询存储引擎 - 调用存储引擎的api - 返回客户端。

#### 客户端/服务端通信

半双工通信：在任何一个时刻，要么是有服务器向客户端发送数据，要么是客户端向服务端发送数据，这两个动作不能同时发生，所以我们无法也无需将一个消息切成小块进 行传输。

查询状态：对于一个MySQL连接，或者说一个线程，时刻都有一个状态来标识这个连接正在做什么。show full processlist。

> Sleep
> 线程正在等待客户端发送数据
> Query
> 连接线程正在执行查询
> Locked
> 线程正在等待表锁的释放
> Sorting result
> 线程正在对结果进行排序
> Sending data
> 向请求端返回数据
> 可通过kill {id}的方式进行连接的杀掉

#### 查询缓存

mysql是默认关闭的，坑点：

> 如果对一个表进行了更改，那么这个表涉及到的缓存都会失效。试用场景：以读为主的场景。
>
> 查询之前必须检查是否命中缓存，浪费计算资源。
>
> 把查询结果放入缓存，额外的系统消耗。

#### 查询优化处理

如何找到最优的执行计划：调整条件位置、覆盖索引扫描、子查询优化、提前终止查询（limit）、in的优化。

![page28image50019984.jpg](http://ww3.sinaimg.cn/large/006tNc79ly1g61pkgm390j30tm0phac6.jpg) 

##### 执行计划-id

> id相同，执行顺序由上至下
>
> id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行

##### 执行计划-select_type

> 区分普通查询、联合查询、子查询等

##### 执行计划-table

> 查询涉及到的表

##### 执行计划-type

指标值，从好到坏依次是：

*system > const > eq_ref > ref > range > index > ALL*

> System：表只有一行记录（等于系统表）
>
> Const：索引一次就找到了，主键索引或者唯一索引
>
> Eq_ref：唯一索引扫描
>
> ref：非唯一索引
>
> range：只检索给定范围的行，使用一个索引来选择行
>
> index：索引全表扫描，把索引从头到尾扫一遍
>
> all：遍历全表

##### 执行计划-其他

> possible_keys 查询过程中有可能用到的索引
>
> key 实际使用的索引，如果为null，则没有使用索引
>
> rows 大致估算出找到所需要的记录所需要读取的行数
>
> filtered 返回结果的行占需要读到的行的百分比，越大越好

##### 执行计划-extra

十分重要的额外信息

> Using filesort：使用一个外部文件进行了排序，而不是按照表内的索引进行排序读取
>
> using temporary：使用临时表保存中间结果，对查询结果排序时使用了临时表，常见于order by 或 group by
>
> Using index：覆盖索引，效率高
>
> using where：使用了where过滤条件

#### 查询执行引擎

调用插件式的存储引擎的原子API的功能进行执行计划的执行

#### 返回给客户端

增量返回结果，MySQL逐步返回数据。好处：MySQL服务器无需保存过多的数据，浪费内存，用户体验好，马上就拿到了数据。

#### 如何定位慢SQL

慢查询日志配置，慢查询日志分析。

### 事务

数据库操作的最小工作单元，事务是一组不可再分割的操作集合。

> 原子性(Atomicity) 最小的工作单元，整个工作单元要么一起提交成功，要么全部失败回滚
> 一致性(Consistency) 事务中操作的数据及状态改变是一致的，即写入资料的结果必须完全符合预设的规则，
> 不会因为出现系统意外等原因导致状态的不一致
> 隔离性(Isolation) 一个事务所操作的数据在提交之前，对其他事务的可见性设定(一般设定为不可见)
> 持久性(Durability) 事务所做的修改就会永久保存，不会因为系统意外导致数据的丢失

并发事务带来的那些问题

> 脏读：一个事务读取到了另外一个事务未提交的数据，一旦另外的一个事务回滚呢，这个数据就变成脏数据了。
>
> 丢失修改：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
>
> 不可重复读：在同一个事务中多次读取同一数据，得到的结果不一样。
>
> 幻读：在同一个事务中多次按照同样的条件查询，会发现多了一些原本不存在的记录。
>
> 不可重复读和幻读的区别：
>
> 不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。

事务四种隔离级别

> Read Uncommitted(未提交读) --未解决并发问题 事务未提交对其他事务也是可见的，脏读(dirty read)
> Read Committed(提交读) --解决脏读问题 一个事务开始之后，只能看到自己提交的事务所做的修改，不可重复读(nonrepeatable read)
> Repeatable Read (可重复读) --解决不可重复读问题 在同一个事务中多次读取同样的数据结果是一样的，这种隔离级别未定义解决幻读的问题。MySQL的默认隔离级别。
> Serializable(串行化) --解决所有问题 最高的隔离级别，通过强制事务的串行执行。

| 事务隔离级别 | 脏读   | 不可重复读 | 幻读               |
| ------------ | ------ | ---------- | ------------------ |
| 读未提交     | 可能   | 可能       | 可能               |
| 读已提交     | 不可能 | 可能       | 可能               |
| 可重复读     | 不可能 | 不可能     | **对innodb不可能** |
| 串行化       | 不可能 | 不可能     | 不可能             |

隔离级别到底如何实现的呢？锁、MVCC

### 锁

> 锁定粒度:表锁 > 行锁
> 加锁效率:表锁 > 行锁 
> 冲突概率:表锁 > 行锁 
> 并发性能:表锁 < 行锁

概念

> 共享锁：读锁，多个事务对同一个数据共享一把锁，只能读不能修改。select ... lock in share mode
> 排他锁：写锁，排它锁不能和其他锁共享，只有获取排它锁的事务才能对数据行进行读取和修改（其他事务要读取数据可来自快照），delete/insert/update自动加排它锁，select * from xxx where id = xx for update
> 意向共享锁：一个数据行加共享锁之前必须先获得表的意向共享锁。另类的表锁。数据操作之前自动加的。
> 意向排他锁：一个数据行加排它锁之前必须先获得表的意向排它锁。另类的表锁。数据操作之前自动加的。
> 表锁与行锁的区别：**innodb的行锁其实是*对索引进行加锁*，只有通过索引条件进行加锁，innodb才会使用行级锁，不然会使用表级锁。**

#### 行锁的算法

- 记录锁
  select * from t where id = 4 for update；id=4这条记录存在，锁住4这条记录。
- 临键锁 next-key（默认）可以解决幻读：这就是innodb可重复读的事务隔离级别解决了幻读问题。
  比方说有记录id 1  4  7  10 四条记录  select * from t where id>5 and id<9 for update; 锁住 （4，7】（7，10】   即没释放锁之前，不能插入5，6，8，9，不能更改7，10
- 间隙锁 gap ：记录不存在，临键锁退化成间隙锁
  比方说有记录id 1  4  7  10 四条记录  select * from t where id>4 and id<6 for update; 锁住 （4，7）   即没释放锁之前，不能插入5，6 
  select * from t where id >10 for update;锁住了大于10的数据行，即没释放锁之前，不能插入10之后的数据。

#### 死锁

介绍

> 多个并发事务
>
> 每个事务都持有锁或者已经在等待锁
>
> 每个事务都需要再继续持有锁
>
> 事务之间产生加锁的循环等待，形成死锁

避免

> 类似的业务逻辑以固定的顺序访问表和行。 
> 大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。
> 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。
> 降低隔离级别，如果业务允许，将隔离级别调低也是较好的选择
> 为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添 加上锁(或者说是表锁)

### MVCC

多版本控制，仅innodb支持，应对高并发事务，MVCC比单纯的加锁更搞笑。用来避免写操作的阻塞，从而引发读操作的并发问题。每个数据行后面加上两个字段：数据行的版本号、删除版本号。

#### Undo log

在MySQL innodb中用来实现多版本控制。

> 开始事务前，即对数据进行操作前，把要用到的数据进行备份，如果rollback，就可以用到这些备份数据进行回滚到事务前，实现了事务的**原子性**，还可以防止脏读（事务未提交之前，其他并发事务读取的是备份中的数据，即为快照读）；

![image-20190812092547689](http://ww4.sinaimg.cn/large/006tNc79ly1g61pko0oxzj319a0mm142.jpg)

- 快照读：

  快照版本，历史版本，普通的select就是快照读，cache（原本数据）+undo（事务修改过得数据）两部分组成

- 当前读：

  最新版本，通过锁机制保证读取的数据无法通过其他事务进行修改，UPDATE DELETE INSERT SELECT..LOCK IN SHARE MODE SELECT...FOR UPDATE都是当前读

#### Redo log

重做，最新的数据备份到一个地方，为了事务的**持久化**而产生的产物，防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redolog进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。

![image-20190812093419779](http://ww1.sinaimg.cn/large/006tNc79ly1g61pkt5d2dj314k0r6ds8.jpg)

### 配置优化

#### connection的内存配置

sort_buffer_size排序缓存区默认256K，join_buffer_size关联查询缓冲区默认256k，上述配置4000连接占用内存:4000*(0.256M+0.256M) = 2G

#### Innodb_buffer_pool_size

innodb buffer/cache的大小(默认128M)
Innodb_buffer_pool
     数据缓存
     索引缓存
     缓冲数据
     内部结构
大的缓冲池可以减小多次磁盘I/O访问相同的表数据以提高性能 参考计算公式:
Innodb_buffer_pool_size = (总物理内存 - 系统运行所用 - connection 所用)* 90%

#### MySQL innodb 数据预热

因为mysql热点数据都在innodb buffer pool中，如果mysql突然关闭，buffer pool被清空！所有数据都需要从硬盘加载至内存中的buffer pool，当需要某个数据时，才从硬盘拿取,导致速度异常慢！这个时候，我们可以将一些数据手动加载至buffer pool，称为人为预热！当然，还有一种方式，在mysql正常关闭的时候，将内存中的buffer pool备份值硬盘！在下次开启时，将该备份导入至buffer pool！这是5.6的快速预热特性！前提是正常关闭，如果是突然关闭或者kill -9关闭，就需要手动预热了！

### 数据库表设计

第一范式：每一列只有一个单一的值，不可再拆分

第二范式：每一行都有主键能进行区分

第三范式：每一个表都不包含其他表已经包含的非主键信息

> 充分满足第一范式将为表建立大量的列，列的数据过多会导致性能下降，影响持久化的性能。
>
> 过分满足第三范式会造成太多的表关联，表的关联操作将带来额外的内存和性能开销。
>
> innodb使用外键关系进行数据的完整性保证，外键表中数据的修改会导致innodb引擎约束进行检查，就带来了额外的开销。

### MySQL分区

根据一定的规则，数据库把一个表分成多个更小的、更容易管理的部分。分区对于应用来说是完全透明的，不影响应用的业务逻辑。每个分区都是一个独立的对象，可以独立处理。
1、查询优化，热点数据归类到一个分区或者多个分区内，查询的时候就不用去查剩下的那些分区，增大查询效率；
2、涉及到例如SUM()和COUNT()这样聚合函数的查询，可以很容易地进行并行处理；
3、分区表的更易管理，比如删除过去某一时间的历史数据，直接执行truncate，或者狠点drop整个分区，这比detele删除效率更高；
4、range分区、list分区、hash分区（你所要做的只是基于将要被哈希的列值指定一个列值或表达式，以及指定被分区的表将要被分割成的分区数量。）、key分区、hash分区：分散热点读，确保数据在各个分区尽可能平均分布。常规HASH分区（取模）和线性HASH分区，因为常规HASH分区的算法是取模，那么新增一个分区的代价非常高，所有的数据都需要重新计算过，所以出现了线性HASH分区。

### SQL调优

[联合查询案例](https://mp.weixin.qq.com/s/tcEoMlz2rdWLsO5q5lO0gw)

[分页查询案例](https://mp.weixin.qq.com/s/le6ue-8q9T20WWWFw8fvuQ)

sql调优总结：
1、列类型尽量定义成数值类型，且长度尽可能短，如主键和外键，类型字段等等；
2、建立单列索引，根据需要建立多列联合索引；
3、当单个列过滤之后还有很多数据，那么索引的效率将会比较低，即列的区分度较低，那么如果在多个列上建立索引，那么多个列的区分度就大多了，将会有显著的效率提高；
4、根据业务场景建立覆盖索引；
5、只查询业务需要的字段，如果这些字段被索引覆盖，将极大的提高查询效率；
6、多表连接的字段上需要建立索引，这样可以极大的提高表连接的效率；
7、where条件字段上需要建立索引，排序字段上需要建立索引，分组字段上需要建立索引；
8、Where条件上不要使用运算函数，以免索引失效；
9、使用短索引：如果对字符串进行索引，应该指定一个前缀长度，节省索引空间，一个磁盘块放更多的关键字，减少磁盘IO操作次数；
10、不要过度使用索引：insert update会更改索引。
11、主键索引选择：最常访问条件的列作为主键。innodb普通索引都包含主键的键值，所以主键要尽可能选择较短的数据类型，有效的减少索引占有磁盘空间；

12、show profile：再做SQL优化的时候，帮助我们了解时间消耗在哪里；
13、order by优化：减少using filesort，通过索引直接返回数据，WHERE条件和ORDER BY使用相同的索引。适当加大sort_buffer_siza排序区，尽量让排序在内存中完成，而不是通过创建临时表放在文件中进行。尽量使用select 字段而不是select * ，可以减少排序区的使用。
14、MySQL分页优化：1、使用覆盖索引，主键关联回表查询；2、limit m n 改成limit n，只适合排序字段不会出现重复字段。

15、明显不会出现重复数据时候使用union all而不是union，union会进行去重动作；

16、超过100万行的批量写（UPDATE\INSERT\DELETE）操作，要分批次进行操作。大批量的操作会导致主从延迟：主库上执行完成后才能同步到从库；大量产生binlog日志传输到从库也会导致主从延迟；在同一个事务中进行，会造成表中大批量数据进行锁定，从而导致大量的阻塞，占满连接，从而使应用变得很慢。

17、对于大表修改表结构会导致严重的锁表操作，尤其是生产环境，故必须使用pt-online-schena-change

### SQL在MYSQL中如何执行

连机器-查询缓存（MySQL8.0版本会移除）-解析器-优化器-执行器（调用存储引擎API返回数据）

更新语句比查询语句多了一个记录日志的操作。1、更改数据后把数据保存到内存（此刻还未把数据flush到硬盘中）；2、记录redo log（innodb引擎专有）状态为prepared；3、记录binlog（每个存储引擎都有），告诉redo log可以进行提交；4、更新完成；

### mycat

数据库产生性能瓶颈的原因：数据库连接数、表数据量、硬件资源（磁盘IO）。。。。
**解决方案：**  

- 读写分离（基础MySQL的主从复制）
- 分库分表，对数据的库表进行拆分，用分片的方式对数据进行管理。
- 垂直拆分：比如单库拆分成用户库、订单库、账户库。这个是根据功能来进行拆分。
- 水平拆分：一般来说，简单的水平切分主要是将某个表再依照某个字段的某种规则来分散到多个表之中。每一个表中包括一部分数据。将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

**分库分表后引入的问题：**

- 分布式事务：1、使用分布式事务中间件 2、使用MySQL自带的针对跨库的事务一致性方案(XA),不过性能要比单库的慢10倍左右。3、能否避免掉跨库操作(比如将用户和商品放在同一个库中)
- 跨库join问题：粗略的解决方法： 全局表：基础数据，所有库都拷贝一份。 字段冗余：这样有些字段就不用join去查询了。 系统层组装：分别查询出所有，然后组装起来，较复杂。
- 横向扩容问题：当我们使用HASH取模做分表的时候,针对数据量的递增,可能需要动态的增加表,此时就需要考虑因为reHash导致数据迁移的问题。
- 结果集合并、排序的问题：因为我们是将数据分散存储到不同的库、表里的，当我们查询指定数据列表时，数据来源于不同的子库或者子表，就必然会引发结果集合并、排序的问题。如果每次查询都需要排序、合并等操作，性能肯定会受非常大的影响。走缓存可能一条路!

**MySQL基于binlog的主从复制原理：**

                           1. master将操作记录到二进制日志(binary log)中 (这些记录叫做二进制日志事件，binary log events)
                           2. Slave通过I/O Thread异步将master的binary log events拷贝到它的中继日志(relay log);
                           3. Slave执行relay日志中的事件，匹配自己的配置 将需要执行的数据，在slave服务上执行一遍从 而达到复制数据的目的。

mycat的分片规则：连续分片（按照日期）、离散分片（取模、一致性hash）、综合分片（结合上面两种）。另外一致性hash的优点是扩容的时候迁移数据量比较少，实际节点少，会造成数据不均匀分布，这个时候需要增加虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍。